{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModel, AutoTokenizer\n",
    "\n",
    "# model_name = 'vinai/bartpho-word-base'\n",
    "model_name = 'vinai/phobert-base-v2'\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model_name)\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chỉ lấy những từ có trong vocab của model, nhưng đã train model word2vec rồi.\n",
    "vocab = tokenizer.get_vocab()\n",
    "vocab_list = list(vocab.keys())\n",
    "\n",
    "def filter_sentence(sentences, vocab_list):\n",
    "    filtered_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        filtered_words = [word for word in words if word in vocab_list]\n",
    "        filtered_sentences.append(' '.join(filtered_words))\n",
    "\n",
    "    return filtered_sentences\n",
    "\n",
    "\n",
    "filtered_sentence = filter_sentence(text_processed, vocab_list)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some test about automodel classification.\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "text = \"Tôi là sinh viên trường đại học bách khoa hà nội\"\n",
    "t = classifier(text,\n",
    "        candidate_labels=keyword_list,\n",
    "    )\n",
    "print(t)\n",
    "\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "logits = nli_model(**inputs).logits\n",
    "print('logits', logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "print('keyword_list', keyword_list)\n",
    "predictions = []\n",
    "for post in filtered_sentence:\n",
    "    print('post', post[:120])\n",
    "    try:\n",
    "        t = classifier(post,\n",
    "            candidate_labels=keyword_list,\n",
    "        )\n",
    "        predictions.append(t)\n",
    "    except Exception as e:\n",
    "        print('e', e, post)\n",
    "        continue\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "def get_small_part(x):\n",
    "    x['labels'] = x['labels'][0:2]\n",
    "    x['scores'] = x['scores'][0:2]\n",
    "    return x\n",
    "\n",
    "predictions = list(map(get_small_part, predictions))\n",
    "df_predict = pd.DataFrame(predictions, columns=[\"sequence\", \"labels\", \"scores\"])\n",
    "\n",
    "print(df_predict)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
